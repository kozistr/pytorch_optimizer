## Change Log

### Feature

* Implement PAdam optimizer (#186)
  * [Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks](https://arxiv.org/abs/1806.06763) 
* Implement LOMO optimizer (#188)
  * [Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://arxiv.org/abs/2306.09782) 
* Implement loss functions (#189)
  * BCELoss
  * BCEFocalLoss
  * FocalLoss : [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)
  * FocalCosineLoss : [Data-Efficient Deep Learning Method for Image Classification Using Data Augmentation, Focal Cosine Loss, and Ensemble](https://arxiv.org/abs/2007.07805)
  * DiceLoss : [Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations](https://arxiv.org/abs/1707.03237v3)
  * LDAMLoss : [Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss](https://arxiv.org/abs/1906.07413)
  * JaccardLoss
  * BiTemperedLogisticLoss : [Robust Bi-Tempered Logistic Loss Based on Bregman Divergences](https://arxiv.org/abs/1906.03361)

## Diff

[2.10.1...2.11.0](https://github.com/kozistr/pytorch_optimizer/compare/v2.10.1...v2.11.0)
