## Change Log

### Feature

* Implement `Refined Schedule-Free AdamW` optimizer. (#409, #414)
    * [Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training](https://arxiv.org/abs/2507.09846)
    * You can use this variant by setting `decoupling_c` parameter in the `ScheduleFreeAdamW` optimizer.

### Update

* Re-implement `Muon` and `AdaMuon` optimizers based on the recent official implementation. (#408, #410)
    * Their definitions have changed from the previous version, so please check out the documentation!

### CI

* Add some GitHub actions to automate some processes. (#411, #412, #413)
